import streamlit as st
import pandas as pd
import requests
from io import BytesIO
import time
import re

# ë„¤ì´ë²„ ì¿ í‚¤ì™€ Authorization í† í° í•˜ë“œì½”ë”©
NAVER_COOKIE = "NNB=BNRWYFSV5QCWQ; NAC=aHfIDIBKjunGA; _fwb=53hk3J7S4SJqiwRur46zDt.1745741103362; _fwb=53hk3J7S4SJqiwRur46zDt.1745741103362; nhn.realestate.article.rlet_type_cd=A01; nhn.realestate.article.trade_type_cd=\"\"; nhn.realestate.article.ipaddress_city=4100000000; NACT=1; landHomeFlashUseYn=Y; SRT30=1751262643; SRT5=1751263329; realestate.beta.lastclick.cortar=4100000000; REALESTATE=Mon%20Jun%2030%202025%2015%3A05%3A09%20GMT%2B0900%20(Korean%20Standard%20Time); PROP_TEST_KEY=1751263509586.3171124cee5dac0547c0581f6e378f18ccc4cbd8ac68cdf0a15e08774de17caf; PROP_TEST_ID=3780cec4d8706ce72414a21bf45e987b4ab9b03fc6872d286d2bba344d0a0368; BUC=3WwiU2rSnjvBjQKWa_l5noDr9MuuM71NIIIKTba1Zys="
NAVER_AUTH = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IlJFQUxFU1RBVEUiLCJpYXQiOjE3NTEyNjM1MDksImV4cCI6MTc1MTI3NDMwOX0.QF5wiBIQFeC_U1lJ3wlnioozAbXBgUvaC5rHWlOAzho"

# ë²•ì •ë™ì½”ë“œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (íƒ­ êµ¬ë¶„)
law_df = pd.read_csv('law_code.txt', sep='\t', dtype=str, encoding='cp949')
law_df = law_df[law_df['íì§€ì—¬ë¶€'] == 'ì¡´ì¬']  # íì§€ëœ ë™ ì œì™¸

# ì‹œ/ë„, ì‹œ/êµ°/êµ¬, ë™/ì/ë©´ ì»¬ëŸ¼ ë¶„ë¦¬
def split_law_name(row):
    parts = row['ë²•ì •ë™ëª…'].split()
    return pd.Series({
        'ì‹œë„': parts[0] if len(parts) > 0 else '',
        'ì‹œêµ°êµ¬': parts[1] if len(parts) > 1 else '',
        'ë™': parts[2] if len(parts) > 2 else ''
    })
law_df = pd.concat([law_df, law_df.apply(split_law_name, axis=1)], axis=1)

# ë¶€ë™ì‚° ìœ í˜• ë§¤í•‘ (ì˜ˆì‹œ)
TYPE_CODE = {
    'ì‚¬ë¬´ì‹¤': 'SMS',
    'ìƒê°€': 'SG',
    'ì•„íŒŒíŠ¸': 'APT',
    'ì˜¤í”¼ìŠ¤í…”': 'OPST',
}

def parse_korean_price(val):
    if not val or val == 'ì—†ìŒ':
        return 0
    val = val.replace(',', '').replace(' ', '')
    match = re.match(r'(?:(\d+)ì–µ)?(\d+)?', val)
    if not match:
        return 0
    uk = int(match.group(1)) if match.group(1) else 0
    man = int(match.group(2)) if match.group(2) else 0
    return uk * 10000 + man

def collect_real_estate_data(cortarNo, property_type, price_min=0, price_max=900000000, area_min=0, area_max=900000000, page=1, cookie_str=None, auth_token=None, full_address=None):
    realEstateType = TYPE_CODE.get(property_type, 'SMS')
    url = "https://new.land.naver.com/api/articles"
    params = {
        "cortarNo": cortarNo,
        "order": "rank",
        "realEstateType": realEstateType,
        # ê°€ê²© ë²”ìœ„ëŠ” ì„ëŒ€ë£Œ(rentPrc) ê¸°ì¤€
        "rentPriceMin": price_min,
        "rentPriceMax": price_max,
        # ë©´ì  ë²”ìœ„ëŠ” ì „ìš©ë©´ì (area2) ê¸°ì¤€
        "area2Min": area_min,
        "area2Max": area_max,
        "page": page,
        "priceType": "RETAIL",
    }
    headers = {
        "User-Agent": "Mozilla/5.0",
        "Referer": "https://new.land.naver.com/",
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "ko-KR,ko;q=0.9",
        "Connection": "keep-alive",
    }
    if cookie_str:
        headers["Cookie"] = cookie_str
    if auth_token:
        headers["authorization"] = f"Bearer {auth_token}"
    response = requests.get(url, params=params, headers=headers)
    if response.status_code != 200:
        st.warning(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
        return pd.DataFrame()
    data = response.json()
    articles = data.get('articleList', [])
    if not articles:
        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    # ì£¼ì†Œ ì²˜ë¦¬
    if full_address is None:
        global sido, sigungu, dong
        full_address = f"{sido} {sigungu} {dong}"
    rows = []
    for art in articles:
        floor_info = art.get('floorInfo', '')
        if '/' in floor_info:
            floor_split = floor_info.split('/')
            floor_current = floor_split[0].strip()
            floor_total = floor_split[1].strip()
        else:
            floor_current = floor_info
            floor_total = floor_info
        rows.append({
            'ë§¤ë¬¼ëª…': art.get('articleName'),
            'ë³´ì¦ê¸ˆ(ë§Œì›)': parse_korean_price(art.get('dealOrWarrantPrc')),
            'ì„ëŒ€ë£Œ(ë§Œì›)': parse_korean_price(art.get('rentPrc')),
            'ì£¼ì†Œ': full_address,
            'ê³„ì•½ë©´ì (ã¡)': art.get('area1'),
            'ì „ìš©ë©´ì (ã¡)': art.get('area2'),
            'í•´ë‹¹ì¸µ': floor_current,
            'ì „ì²´ì¸µ': floor_total,
            'ë§¤ë¬¼ID': art.get('articleNo'),
        })
    df = pd.DataFrame(rows)
    return df

def collect_all_real_estate_data(cortarNo, property_type, price_min, price_max, area_min, area_max, cookie_str=None, auth_token=None, max_pages=5, full_address=None):
    all_df = []
    for page in range(1, max_pages+1):
        df = collect_real_estate_data(
            cortarNo, property_type, price_min, price_max, area_min, area_max,
            page=page, cookie_str=cookie_str, auth_token=auth_token, full_address=full_address
        )
        if df.empty:
            break
        all_df.append(df)
        if len(df) < 20:
            break
    if all_df:
        return pd.concat(all_df, ignore_index=True)
    else:
        return pd.DataFrame()

st.title("ğŸ¢ ë¶€ë™ì‚° ì‹œì„¸ ì¡°ì‚¬ê¸° (ì „êµ­ í–‰ì •êµ¬ì—­ ì§€ì›)")

# ì‹œ/ë„ ì„ íƒ
sido_list = law_df[law_df['ë²•ì •ë™ì½”ë“œ'].str.endswith('00000000')]['ì‹œë„'].unique()
sido = st.selectbox('ì‹œ/ë„ ì„ íƒ', sido_list)

# ì‹œ/êµ°/êµ¬ ì„ íƒ
sigungu_df = law_df[(law_df['ì‹œë„'] == sido) & (law_df['ë²•ì •ë™ì½”ë“œ'].str.endswith('00000')) & (~law_df['ë²•ì •ë™ì½”ë“œ'].str.endswith('00000000'))]
sigungu_list = sigungu_df['ì‹œêµ°êµ¬'].unique()
sigungu = st.selectbox('ì‹œ/êµ°/êµ¬ ì„ íƒ', sigungu_list)

# ë™/ì/ë©´ ì„ íƒ
dong_df = law_df[
    (law_df['ì‹œë„'] == sido) &
    (law_df['ì‹œêµ°êµ¬'] == sigungu) &
    (~law_df['ë²•ì •ë™ì½”ë“œ'].str.endswith('00000'))
]
dong_list = dong_df['ë™'].dropna().unique()
dong = st.selectbox('ë™/ì/ë©´ ì„ íƒ', dong_list)

# ì„ íƒëœ ë™ì˜ ë²•ì •ë™ì½”ë“œ
cortarNo = dong_df[dong_df['ë™'] == dong]['ë²•ì •ë™ì½”ë“œ'].values[0]

property_type = st.selectbox("ë¶€ë™ì‚° ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”", list(TYPE_CODE.keys()))

# ì„ëŒ€ë£Œ(ë§Œì› ë‹¨ìœ„) ìŠ¬ë¼ì´ë”: 0~10000
rent_range = st.slider(
    "ì„ëŒ€ë£Œ ë²”ìœ„(ë§Œì›)",
    min_value=0, max_value=10000, value=(0, 10000), step=10
)
price_min = rent_range[0] * 10000
price_max = rent_range[1] * 10000

# ì „ìš©ë©´ì (ã¡) ìŠ¬ë¼ì´ë”: 0~10000
area_range = st.slider(
    "ì „ìš©ë©´ì  ë²”ìœ„(ã¡)",
    min_value=0, max_value=10000, value=(0, 10000), step=1
)
area_min = area_range[0]
area_max = area_range[1]

uploaded_file = st.file_uploader("ë²•ì •ë™ëª… ë¦¬ìŠ¤íŠ¸ ì—‘ì…€ ì—…ë¡œë“œ (ë²•ì •ë™ëª… ì»¬ëŸ¼ í•„ìˆ˜)", type=["xlsx"])

if uploaded_file is not None:
    if st.button("ì‹œì„¸ ì¡°ì‚¬ ì‹œì‘"):
        input_df = pd.read_excel(uploaded_file)
        if 'ë²•ì •ë™ëª…' not in input_df.columns:
            st.error('ì—‘ì…€ì— ë°˜ë“œì‹œ "ë²•ì •ë™ëª…" ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.')
        else:
            law_names = input_df['ë²•ì •ë™ëª…'].dropna().unique()
            result_dict = {}
            for law_name in law_names:
                row = law_df[law_df['ë²•ì •ë™ëª…'] == law_name]
                if row.empty:
                    continue
                cortarNo = row['ë²•ì •ë™ì½”ë“œ'].values[0]
                df = collect_all_real_estate_data(
                    cortarNo, 'ì‚¬ë¬´ì‹¤', 0, 100000000, 0, 10000,
                    cookie_str=NAVER_COOKIE, auth_token=NAVER_AUTH, max_pages=5,
                    full_address=law_name
                )
                result_dict[law_name] = df
            if result_dict:
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    for sheet_name, df in result_dict.items():
                        if not df.empty:
                            safe_sheet_name = sheet_name[:31].replace('/', '-')
                            df.to_excel(writer, index=False, sheet_name=safe_sheet_name)
                st.download_button(
                    label="ì—‘ì…€ ë‹¤ìš´ë¡œë“œ(ë²•ì •ë™ë³„ ì‹œíŠ¸)",
                    data=output.getvalue(),
                    file_name='naver_land_multi_sheet.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
            else:
                st.warning('ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. (ë²•ì •ë™ëª…ì´ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ê²°ê³¼ ì—†ìŒ)')
else:
    # ì—…ë¡œë“œ íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë‹¨ì¼ ì¡°íšŒ UI ë° ë²„íŠ¼ ë…¸ì¶œ
    # (ì•„ë˜ ê¸°ì¡´ ë‹¨ì¼ ì¡°íšŒ ì½”ë“œ ìœ ì§€)
    if st.button("ì‹œì„¸ ì¡°ì‚¬ ì‹œì‘"):
        with st.spinner("ì¡°ì‚¬ ì¤‘ì…ë‹ˆë‹¤..."):
            df = collect_all_real_estate_data(
                cortarNo, property_type, price_min, price_max, area_min, area_max,
                cookie_str=NAVER_COOKIE, auth_token=NAVER_AUTH,
                max_pages=5
            )
            if not df.empty:
                st.dataframe(df)
                def to_excel(df):
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        df.to_excel(writer, index=False)
                    return output.getvalue()
                st.download_button(
                    label="ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                    data=to_excel(df),
                    file_name='naver_land_api_results.xlsx',
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
            else:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.") 